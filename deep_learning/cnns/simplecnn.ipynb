{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14de2316"
      },
      "source": [
        "*<small>Last updated: 2026-02-19 22:39:14 UTC | Student Version (No Solutions)</small>*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR-z4muh9jgn"
      },
      "source": [
        "**Student Version** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Instructor Version**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/mtgca/7d52f0b7b63c6317f0151fe1505d85c7/SimpleCNN.ipynb) &nbsp;&nbsp;&nbsp; [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mtgca/DL-Labs/blob/main/01%20CNNs/SimpleCNN.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPAcSBerZalE"
      },
      "source": [
        "# CNN básica usando PyTorch Lightning\n",
        "## Objetivos\n",
        "\n",
        "- Construir una red neuronal usando funciones de PyTorch\n",
        "- Importar bases de datos en batches\n",
        "- Entrenar una CNN para clasificación de imagenes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulGyz-4eZowy"
      },
      "source": [
        "## Instalar e importar bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QPIro1jdJ0k"
      },
      "outputs": [],
      "source": [
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT1MMnNbZVKr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVgRHTZF62YH"
      },
      "source": [
        "# Performance Optimization Through Environment Detection\n",
        "The fundamental difference between VSCode remote containers and Google Colab lies in how they communicate with the user interface. In VSCode remote environments, your code executes inside a Docker container or remote server, and all output—including progress bar updates, print statements, and data transfers—must traverse the network to reach your local VSCode client. When PyTorch Lightning's progress bar updates hundreds of times per epoch (once per batch), these frequent UI updates create massive network overhead, with each update requiring a round-trip between the container and your client. Similarly, spawning multiple data loader worker processes in a remote container creates severe inter-process communication (IPC) bottlenecks, as each worker must serialize and transfer data through multiple layers. In contrast, Google Colab runs in a browser with a local connection to its backend servers, making these operations far less costly.\n",
        "\n",
        "This environment detection code automatically identifies whether you're in a constrained remote environment and adjusts critical settings accordingly. For VSCode remote, it sets num_workers=0 to eliminate multi-process overhead (letting the GPU handle parallelism instead), disables progress_bar to eliminate hundreds of network round-trips per epoch, and reduces logging frequency by 10x. These changes transform training from 10-100x slower than native to near-native GPU speed—typically resulting in 5-10x performance improvement. For Colab or local environments where these bottlenecks don't exist, it maintains standard settings with progress bars and parallel data loading. This automatic adaptation means you can run the same notebook efficiently in both environments without manual configuration changes, ensuring optimal performance regardless of where you execute your training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0UQyE3n5fdX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "def is_remote_vscode():\n",
        "    \"\"\"Detect if running in VSCode remote container/SSH environment.\n",
        "\n",
        "    Uses DMI Product information to distinguish between VSCode Remote and Google Colab.\n",
        "    Google Colab runs on \"Google Compute Engine\" VMs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if os.path.exists('/sys/class/dmi/id/product_name'):\n",
        "            with open('/sys/class/dmi/id/product_name', 'r') as f:\n",
        "                product = f.read().strip()\n",
        "                print(\"DMI:\", product)\n",
        "                # Google Colab runs on Google Compute Engine\n",
        "                if 'Google' in product or 'Compute Engine' in product:\n",
        "                    return False  # This is Google Colab\n",
        "        # If not Google Compute Engine, assume VSCode Remote/Local\n",
        "        return True\n",
        "    except:\n",
        "        # If we can't read DMI, assume local/non-Colab\n",
        "        return True\n",
        "\n",
        "# Detect environment and set optimal configurations\n",
        "IS_REMOTE = is_remote_vscode()\n",
        "print(f\"Environment detected: {'VSCode Remote' if IS_REMOTE else 'Google Colab'}\")\n",
        "\n",
        "# Performance-optimized settings based on environment\n",
        "if IS_REMOTE:\n",
        "    ENABLE_PROGRESS_BAR = False  # Disable progress bar updates over network\n",
        "else:\n",
        "    ENABLE_PROGRESS_BAR = True\n",
        "print(f\"Progress bar enabled: {ENABLE_PROGRESS_BAR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZzWCsUbzLj"
      },
      "source": [
        "## Definición de hiperparámetros de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5M5fDxUb4f7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 60\n",
        "LEARNING_RATE = 0.0001\n",
        "NUM_WORKERS = 4 # unidades de procesamiento o hilos\n",
        "CLASES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N5UHClkbWGU"
      },
      "source": [
        "## Preparación de la base de datos: CIFAR-10\n",
        "\n",
        "### CIFAR-10 contiene 60k RGB imágenes de 32x32x3 pixeles distribuidas en 10 clases.\n",
        "\n",
        "*   Grupo de entrenamiento: 50K imágenes\n",
        "*   Grupo de evaluación: 10k imágenes\n",
        "\n",
        "Datasets disponibles en  pytorch https://docs.pytorch.org/vision/stable/datasets.html#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LPGj8th4Cu"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiOprzBWbdOD"
      },
      "outputs": [],
      "source": [
        "# Descargamos dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./datacifar\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./datacifar\", train=False, transform=transforms.ToTensor(), download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJfI9zDbdIU"
      },
      "outputs": [],
      "source": [
        "# Definimos dataloaders para los datasets\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=NUM_WORKERS,\n",
        "                          drop_last=False, # ignora el último batch si el número de muestras no son divisibles para el tamaño de batch\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=NUM_WORKERS,\n",
        "                          drop_last=False,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXTvckCDbdBj"
      },
      "outputs": [],
      "source": [
        "print(\"Número de muestras de entrenamiento:\", len(train_dataset))\n",
        "print(\"Número de muestras de evaluación:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUTK_l3EhHoX"
      },
      "outputs": [],
      "source": [
        "print(\"Número de iteraciones por época:\", len(train_loader))\n",
        "# 1563*32 = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHzrj7uPhCBv"
      },
      "outputs": [],
      "source": [
        "# Visualización de imágenes\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imágenes de entrenamiento\")\n",
        "plt.imshow(np.transpose(torchvision.utils.make_grid(\n",
        "    images,\n",
        "    padding=2,\n",
        "    normalize=True),\n",
        "    (1, 2, 0)))\n",
        "#reorganize dimensions. pytorch uses (batch, channels, height, width)\n",
        "#where each image in pytorch has (channels dim 0, height dim 1, width dim 2) but to plot we need\n",
        "# height, width, channels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeeVYtR8i6pe"
      },
      "outputs": [],
      "source": [
        "# Dimensión de cada imagen\n",
        "print(\"Dimensión de entrada:\", images.shape) # (batch_size, channels_in, W, H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXtAIFr3GQQM"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGCE7RfiMEDn"
      },
      "source": [
        "For torch.nn.BCEWithLogitsLoss\n",
        "clase 2 --> one hot encoding --> [0 0 1 0 0 0 0 0 0 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4Ua4znjYfW"
      },
      "source": [
        "### Definición de CIFAR-10 DataModule para Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTycs3Z6jY1H"
      },
      "outputs": [],
      "source": [
        "class CIFAR_DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_path=\"./\"):\n",
        "        super().__init__()\n",
        "        self.data_path = data_path # donde estará alojado el dataset\n",
        "        self.train_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((28, 28)), # podemos agregar funciones de aumento de datos\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.test_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((28, 28)),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def prepare_data(self): # Método prepare_data es usado para pasos que van a ser ejecutados solo una vez, como descargar el dataset y definir las transformaciones\n",
        "\n",
        "        datasets.CIFAR10(root=self.data_path, download=True)\n",
        "\n",
        "        return\n",
        "\n",
        "    def setup(self, stage=None):   # cargamos el dataset\n",
        "        train = datasets.CIFAR10(\n",
        "            root=self.data_path,\n",
        "            train=True,\n",
        "            transform=self.train_transform,\n",
        "            download=False,\n",
        "        )\n",
        "\n",
        "        self.test = datasets.CIFAR10(\n",
        "            root=self.data_path,\n",
        "            train=False, # False para obtener el grupo de test\n",
        "            transform=self.test_transform,\n",
        "            download=False,\n",
        "        )\n",
        "\n",
        "        # Dividir el grupo de entrenamiento original en entrenamiento y validación\n",
        "\n",
        "        self.train, self.valid = random_split(train, lengths=[int(len(train)*0.9), int(len(train)*0.1)])\n",
        "\n",
        "        print(\"Muestras de entrenamiento:\", len(self.train))\n",
        "        print(\"Muestras de validación:\", len(self.valid))\n",
        "        print(\"Muestras de evaluación:\", len(self.test))\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader = DataLoader(\n",
        "            dataset=self.train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=True, #The drop_last parameter in a PyTorch DataLoader determines how to handle the last batch of data if the total number of samples is not perfectly divisible by the batch_size. If drop_last is set to True, the last batch will be discarded if it contains fewer samples than batch_size. If drop_last is False (the default), the last batch will be smaller than batch_size.\n",
        "            shuffle=True,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        valid_loader = DataLoader(\n",
        "            dataset=self.valid,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=False,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return valid_loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        test_loader = DataLoader(\n",
        "            dataset=self.test,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=False,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubTECZ79mg8E"
      },
      "outputs": [],
      "source": [
        "# Inicizalización de DataModule\n",
        "\n",
        "torch.manual_seed(47)  # especificamos un random seed para reproducibilidad de inicializaciones aleatorias\n",
        "data_module = CIFAR_DataModule(data_path='./datacifar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhuT7Jf6ZtjN"
      },
      "source": [
        "## Definición de la arquitectura de la CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiGrSyqIZOP0"
      },
      "outputs": [],
      "source": [
        "class Simple_CNN(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Calculate padding:\n",
        "        # (N - F + 2*p)/s + 1 = out\n",
        "        # => p = (s(out-1) - N + F)/2\n",
        "\n",
        "        self.features = torch.nn.Sequential( # comienza la secuencia de capas\n",
        "\n",
        "            # in: 28x28x3 => out: 28x28x8\n",
        "            torch.nn.Conv2d(in_channels=3,\n",
        "                            out_channels=8,#number of filters\n",
        "                            kernel_size=(3, 3),\n",
        "                            stride=(1, 1),\n",
        "                            padding=1),  # calculamos padding: (1(28-1) - 28 + 3) / 2 = 1\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # in: 28x28x8 => out: 14x14x8\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                               stride=(2, 2),\n",
        "                               padding=0),  # (2(14-1) - 28 + 2) = 0\n",
        "\n",
        "            # in: 14x14x8 => out: 14x14x16\n",
        "            torch.nn.Conv2d(in_channels=8,\n",
        "                            out_channels=16,\n",
        "                            kernel_size=(3, 3),\n",
        "                            stride=(1, 1),\n",
        "                            padding=1),  # (1(14-1) - 14 + 3) / 2 = 1\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # in: 14x14x16 => out: 7x7x16\n",
        "            torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                               stride=(2, 2),\n",
        "                               padding=0)  # (2(7-1) - 14 + 2) = 0\n",
        "        ) # cerramos la secuencia\n",
        "\n",
        "        # definimos la capa densa de salida\n",
        "\n",
        "        self.output_layer = torch.nn.Linear(7*7*16, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x) #conv blocks, out: 7x7x16, (batch, ...)\n",
        "        # Reestructuramos el último mapa de características en un vector 1D\n",
        "        x = torch.flatten(x, start_dim=1) # aplanamos dimensión 1 porque dimensión 0 es batch_size\n",
        "        x = self.output_layer(x)\n",
        "        return x   # logits del modelo, no son probabilidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHPlyP_tqozr"
      },
      "source": [
        "## Definición del Módulo Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEWxIedCZONS"
      },
      "outputs": [],
      "source": [
        "class Lightning_CNN(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate, classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        # Modelo PyTorch heredado\n",
        "        self.model = model\n",
        "        self.classes = classes\n",
        "\n",
        "        # Guardar hiperparametros en directorio de logs\n",
        "        # Ignora los pesos del modelo\n",
        "        self.save_hyperparameters(ignore=[\"model\"])\n",
        "\n",
        "        # Definición de métricas para cada grupo de datos\n",
        "        self.train_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "        self.valid_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "        self.test_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    # Pasos del proceso forward comunes entre train, val, test\n",
        "    def _shared_step(self, batch):\n",
        "        features, true_labels = batch\n",
        "        logits = self(features) #this calls forward!!!\n",
        "        loss = torch.nn.functional.cross_entropy(logits, true_labels) # cross entropy loss recibe logits y labels como entrada. No recibe probabilidades!\n",
        "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "        predicted_labels = torch.argmax(probs, dim=1)\n",
        "\n",
        "        return loss, true_labels, predicted_labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.train_acc(predicted_labels, true_labels)\n",
        "        self.log(\"train_acc\", self.train_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss  # perdida pasa al optmizador para entrenar la red\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.log(\"valid_loss\", loss)\n",
        "        self.valid_acc(predicted_labels, true_labels)\n",
        "        self.log(\"valid_acc\", self.valid_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.test_acc(predicted_labels, true_labels)\n",
        "        self.log(\"test_acc\", self.test_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkUER95SsFj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAf9UGzLtRbw"
      },
      "source": [
        "## Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4dA83vCZOK1"
      },
      "outputs": [],
      "source": [
        "# Inicialización del modelo\n",
        "\n",
        "pytorch_model = Simple_CNN(num_classes=CLASES)\n",
        "\n",
        "print(pytorch_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0722f11a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "# Assuming pytorch_model is already defined and its input shape is known\n",
        "# For CIFAR10 images of size 28x28 with 3 channels\n",
        "\n",
        "# Move the model to CUDA if available before summarizing\n",
        "if torch.cuda.is_available():\n",
        "    pytorch_model.cuda()\n",
        "\n",
        "summary(pytorch_model, input_size=(3, 28, 28))\n",
        "#Params = (Filter Width x Filter Height x Input Channels + 1) x Number of Filters\n",
        "# (3*3*3 + 1)*8 = 224\n",
        "# (3*3*8+1)*16 = 1168"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C86w3BYUZOIL"
      },
      "outputs": [],
      "source": [
        "# Inicialización del modulo lightning\n",
        "\n",
        "lightning_model = Lightning_CNN(pytorch_model, learning_rate=LEARNING_RATE, classes=CLASES)\n",
        "\n",
        "callback_check = ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"valid_acc\") # guardamos el mejor modelo monitoreado en la acc de validación. Por qué no la de entrenamiento?\n",
        "\n",
        "callback_tqdm = RichProgressBar(leave=False)\n",
        "\n",
        "logger = CSVLogger(save_dir=\"logs/\", name=\"simple-cnn-prob-cifar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a14b5a3b"
      },
      "outputs": [],
      "source": [
        "class CustomLoggingCallback(pl.Callback):\n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        epoch = trainer.current_epoch\n",
        "        train_loss = trainer.callback_metrics.get(\"train_loss\")\n",
        "        valid_loss = trainer.callback_metrics.get(\"valid_loss\")\n",
        "\n",
        "        output_str = f\"Epoch {epoch}: \"\n",
        "        if train_loss is not None:\n",
        "            output_str += f\"Train Loss: {train_loss:.4f}, \"\n",
        "        if valid_loss is not None:\n",
        "            output_str += f\"Valid Loss: {valid_loss:.4f}, \"\n",
        "        output_str += f\"Time per Epoch: {epoch_duration:.2f} seconds\"\n",
        "        print(output_str)\n",
        "\n",
        "custom_logger_callback = CustomLoggingCallback()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf0dXwlmZOFK"
      },
      "outputs": [],
      "source": [
        "#  Inicia entrenamiento\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=NUM_EPOCHS,\n",
        "                    callbacks=[callback_check, custom_logger_callback],\n",
        "                    accelerator=\"auto\",  # Uses GPUs or TPUs if available\n",
        "                    devices=\"auto\",  # Uses all available GPUs/TPUs if applicable\n",
        "                    logger=logger,\n",
        "                    deterministic=False, # Might make your system slower if True, but ensures reproducibility.\n",
        "                    log_every_n_steps=10,\n",
        "                     enable_progress_bar= ENABLE_PROGRESS_BAR)\n",
        "\n",
        "start_time = time.time()\n",
        "trainer.fit(model = lightning_model, datamodule = data_module)\n",
        "\n",
        "runtime = (time.time() - start_time) / 60\n",
        "print(f\"Tiempo de entrenamiento en minutos: {runtime:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aer842ctxNzM"
      },
      "source": [
        "## Graficamos las curvas de aprendizaje del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDI5akWpZOBy"
      },
      "outputs": [],
      "source": [
        "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
        "\n",
        "aggreg_metrics = []\n",
        "agg_col = \"epoch\"\n",
        "for i, dfg in metrics.groupby(agg_col):\n",
        "    agg = dict(dfg.mean())\n",
        "    agg[agg_col] = i\n",
        "    aggreg_metrics.append(agg)\n",
        "\n",
        "df_metrics = pd.DataFrame(aggreg_metrics)\n",
        "df_metrics[[\"train_loss\", \"valid_loss\"]].plot(\n",
        "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
        ")\n",
        "df_metrics[[\"train_acc\", \"valid_acc\"]].plot(\n",
        "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4FDBGQ3xvHd"
      },
      "source": [
        "## Evaluamos el mejor modelo en el grupo de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8ZIocKjZN9a"
      },
      "outputs": [],
      "source": [
        "trainer.test(model = lightning_model, datamodule = data_module, ckpt_path = 'best') # cargamos el mejor checkpoint del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgnPlKj82EBw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}