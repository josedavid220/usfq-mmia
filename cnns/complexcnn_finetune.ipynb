{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0e945b4"
      },
      "source": [
        "*<small>Last updated: 2026-02-19 22:39:14 UTC | Student Version (No Solutions)</small>*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Xb6Apt9jgo"
      },
      "source": [
        "**Student Version** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **Instructor Version**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/mtgca/7d52f0b7b63c6317f0151fe1505d85c7/ComplexCNN_finetune.ipynb) &nbsp;&nbsp;&nbsp; [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mtgca/DL-Labs/blob/main/01%20CNNs/ComplexCNN_finetune.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPAcSBerZalE"
      },
      "source": [
        "# MobileNetV2 usando PyTorch Lightning\n",
        "## Objetivos\n",
        "\n",
        "- Importar un modelo CNN complejo pre-entrenado\n",
        "- Fine-tune un modelo pre-entrenado para clasificacion de imagenes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulGyz-4eZowy"
      },
      "source": [
        "## Instalar e importar bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdIZjBZiT89L"
      },
      "outputs": [],
      "source": [
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb-J1FIra440"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "def is_remote_vscode():\n",
        "    \"\"\"Detect if running in VSCode remote container/SSH environment.\n",
        "\n",
        "    Uses DMI Product information to distinguish between VSCode Remote and Google Colab.\n",
        "    Google Colab runs on \"Google Compute Engine\" VMs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if os.path.exists('/sys/class/dmi/id/product_name'):\n",
        "            with open('/sys/class/dmi/id/product_name', 'r') as f:\n",
        "                product = f.read().strip()\n",
        "                print(\"DMI:\", product)\n",
        "                # Google Colab runs on Google Compute Engine\n",
        "                if 'Google' in product or 'Compute Engine' in product:\n",
        "                    return False  # This is Google Colab\n",
        "        # If not Google Compute Engine, assume VSCode Remote/Local\n",
        "        return True\n",
        "    except:\n",
        "        # If we can't read DMI, assume local/non-Colab\n",
        "        return True\n",
        "\n",
        "# Detect environment and set optimal configurations\n",
        "IS_REMOTE = is_remote_vscode()\n",
        "print(f\"Environment detected: {'VSCode Remote' if IS_REMOTE else 'Google Colab'}\")\n",
        "\n",
        "# Performance-optimized settings based on environment\n",
        "if IS_REMOTE:\n",
        "    ENABLE_PROGRESS_BAR = False  # Disable progress bar updates over network\n",
        "else:\n",
        "    ENABLE_PROGRESS_BAR = True\n",
        "print(f\"Progress bar enabled: {ENABLE_PROGRESS_BAR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT1MMnNbZVKr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "\n",
        "from collections import Counter\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZzWCsUbzLj"
      },
      "source": [
        "## Definición de hiperparámetros de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5M5fDxUb4f7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_WORKERS = 4 # unidades de procesamiento o hilos\n",
        "CLASES = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N5UHClkbWGU"
      },
      "source": [
        "## Preparación de la base de datos: CIFAR-10\n",
        "\n",
        "### CIFAR-10 contiene 60k RGB imágenes de 32x32x3 pixeles distribuidas en 10 clases.\n",
        "\n",
        "*   Grupo de entrenamiento: 50K imágenes\n",
        "*   Grupo de evaluación: 10k imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiOprzBWbdOD"
      },
      "outputs": [],
      "source": [
        "# Descargamos dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root=\"./data\", train=False, transform=transforms.ToTensor(), download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJfI9zDbdIU"
      },
      "outputs": [],
      "source": [
        "# Definimos dataloaders para los datasets\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=NUM_WORKERS,\n",
        "                          drop_last=False, # ignora el último batch si el número de muestras no son divisibles para el tamaño de batch\n",
        "                          shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          num_workers=NUM_WORKERS,\n",
        "                          drop_last=False,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXTvckCDbdBj"
      },
      "outputs": [],
      "source": [
        "print(\"Número de muestras de entrenamiento:\", len(train_dataset))\n",
        "print(\"Número de muestras de evaluación:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUTK_l3EhHoX"
      },
      "outputs": [],
      "source": [
        "print(\"Número de iteraciones por época:\", len(train_loader))\n",
        "# 1563*32 = 50000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHzrj7uPhCBv"
      },
      "outputs": [],
      "source": [
        "# Visualización de imágenes\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    break\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imágenes de entrenamiento\")\n",
        "plt.imshow(np.transpose(torchvision.utils.make_grid(\n",
        "    images[:64],\n",
        "    padding=2,\n",
        "    normalize=True),\n",
        "    (1, 2, 0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeeVYtR8i6pe"
      },
      "outputs": [],
      "source": [
        "# Dimensión de cada imagen\n",
        "print(\"Dimensión de entrada:\", images.shape) # (batch_size, channels_in, W, H)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4Ua4znjYfW"
      },
      "source": [
        "### Definición de CIFAR-10 DataModule para Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTycs3Z6jY1H"
      },
      "outputs": [],
      "source": [
        "class CIFAR_DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_path=\"./\"):\n",
        "        super().__init__()\n",
        "        self.data_path = data_path # donde estará alojado el dataset\n",
        "        self.train_transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((256, 256)),\n",
        "            torchvision.transforms.RandomCrop((224, 224)),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(\n",
        "                (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "        self.test_transform = torchvision.transforms.Compose([\n",
        "            torchvision.transforms.Resize((224, 224)),\n",
        "            torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize(\n",
        "                (0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "    def prepare_data(self): # Método prepare_data es usado para pasos que van a ser ejecutados solo una vez, como descargar el dataset y definir las transformaciones\n",
        "\n",
        "        #datasets.CIFAR10(root=self.data_path, download=True)\n",
        "\n",
        "        return\n",
        "\n",
        "    def setup(self, stage=None):   # cargamos el dataset\n",
        "        train = datasets.CIFAR10(\n",
        "            root=self.data_path,\n",
        "            train=True,\n",
        "            transform=self.train_transform,\n",
        "            download=False,\n",
        "        )\n",
        "\n",
        "        self.test = datasets.CIFAR10(\n",
        "            root=self.data_path,\n",
        "            train=False, # False para obtener el grupo de test\n",
        "            transform=self.test_transform,\n",
        "            download=False,\n",
        "        )\n",
        "\n",
        "        # Dividir el grupo de entrenamiento original en entrenamiento y validación\n",
        "\n",
        "        self.train, self.valid = random_split(train, lengths=[int(len(train)*0.9), int(len(train)*0.1)])\n",
        "\n",
        "        print(\"Muestras de entrenamiento:\", len(self.train))\n",
        "        print(\"Muestras de validación:\", len(self.valid))\n",
        "        print(\"Muestras de evaluación:\", len(self.test))\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader = DataLoader(\n",
        "            dataset=self.train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=True,\n",
        "            shuffle=True,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        valid_loader = DataLoader(\n",
        "            dataset=self.valid,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=False,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return valid_loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        test_loader = DataLoader(\n",
        "            dataset=self.test,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            drop_last=False,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "        )\n",
        "        return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubTECZ79mg8E"
      },
      "outputs": [],
      "source": [
        "# Inicizalización de DataModule\n",
        "\n",
        "torch.manual_seed(47)  # especificamos un random seed para reproducibilidad de inicializaciones aleatorias\n",
        "data_module = CIFAR_DataModule(data_path='./data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhuT7Jf6ZtjN"
      },
      "source": [
        "## Importar la arquitectura MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CmdqeIXXtKz"
      },
      "outputs": [],
      "source": [
        "pytorch_model = torch.hub.load('pytorch/vision:v0.11.0', 'mobilenet_v2', weights='MobileNet_V2_Weights.IMAGENET1K_V1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX3CKKLKXtK0"
      },
      "source": [
        "Modificamos el numero de clases de salida en MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieMFgHBgXtK0"
      },
      "outputs": [],
      "source": [
        "pytorch_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdMwaYTIhXlU"
      },
      "outputs": [],
      "source": [
        "# Example input tensor with shape [32, 3, 224, 224]\n",
        "input_tensor = torch.randn(32, 3, 224, 224)\n",
        "# Forward pass through the feature extractor (excluding classifier)\n",
        "features_ex = pytorch_model.features(input_tensor)  # Shape: [32, 1280, 7, 7]\n",
        "print('Salida del bloque features: ',features_ex.shape)\n",
        "# Apply global average pooling, reducing the spatial dimensions to 1x1\n",
        "global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "pooled_features = global_avg_pool(features_ex)  # Shape: [32, 1280, 1, 1]\n",
        "print('Salida del bloque features after avg pooling: ', pooled_features.shape )\n",
        "# Flatten the tensor\n",
        "flattened_features = torch.flatten(pooled_features, 1)  # Shape: [32, 1280]\n",
        "print('Salida 1D: ', flattened_features.shape )\n",
        "\n",
        "#where is the avg pooling in the model?\n",
        "import inspect\n",
        "print(inspect.getsource(pytorch_model.forward))\n",
        "print(inspect.getsource(pytorch_model._forward_impl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXrfV-fXtK1"
      },
      "outputs": [],
      "source": [
        "# Sobre escribimos el clasificador de la red, el cual es la ultima capa [-1]\n",
        "pytorch_model.classifier[-1] = torch.nn.Linear(\n",
        "        in_features=1280,  # Vector de caracteristicas entregado por MobileNetV2\n",
        "        out_features=10)  # Numero de clases para CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fF3bedrkd1Y"
      },
      "source": [
        "Seleccionamos el número de capas que van a re-entrenarse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOtnGFb4tXIH"
      },
      "outputs": [],
      "source": [
        "pytorch_model.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcycYjTcXtK1"
      },
      "outputs": [],
      "source": [
        "#threshold = 57\n",
        "#for i, param in enumerate(pytorch_model.features.parameters()):\n",
        "#    if i < threshold:\n",
        "#        param.requires_grad = False\n",
        "#    elif i >= threshold:\n",
        "#        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOI11Sb4JsNK"
      },
      "outputs": [],
      "source": [
        "# Definimos cuántos de los primeros bloques (módulos) del extractor de características queremos congelar.\n",
        "# Por ejemplo, congelar los primeros 10 bloques (índices 0 a 9).\n",
        "# Puedes ajustar este número para experimentar con diferentes estrategias de fine-tuning.\n",
        "num_blocks_to_freeze = 1 #puede tomar valores de 0 a 18 (ver pytorch_model.features)\n",
        "\n",
        "# Iterar sobre los módulos (bloques) del extractor de características.\n",
        "for i, child in enumerate(pytorch_model.features.children()):\n",
        "    if i < num_blocks_to_freeze:\n",
        "        # Congelar todos los parámetros de este bloque\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "    else:\n",
        "        # Descongelar todos los parámetros de este bloque\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "# Asegurarse de que el clasificador siempre se entrene\n",
        "for param in pytorch_model.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(f\"Se han congelado los parámetros de los primeros {num_blocks_to_freeze} bloques del extractor de características.\")\n",
        "print(\"Los parámetros de los bloques restantes (y el clasificador) se entrenarán.\")\n",
        "\n",
        "# Imprimir el estado de requires_grad para todos los parámetros del modelo\n",
        "print(\"\\nEstado de requires_grad para cada parámetro del modelo:\")\n",
        "for name, param in pytorch_model.named_parameters():\n",
        "    print(f\"  '{name}': {param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHPlyP_tqozr"
      },
      "source": [
        "## Definición del Módulo Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEWxIedCZONS"
      },
      "outputs": [],
      "source": [
        "class Lightning_CNN(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate, classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.model = model\n",
        "        self.classes = classes\n",
        "\n",
        "        # Guardar hiperparametros en directorio de logs\n",
        "        # Ignora los pesos del modelo\n",
        "        self.save_hyperparameters(ignore=[\"model\"])\n",
        "\n",
        "        # Definición de métricas para cada grupo de datos\n",
        "        self.train_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "        self.valid_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "        self.test_acc = torchmetrics.Accuracy(num_classes = self.classes, task='multiclass')\n",
        "\n",
        "    # Defining the forward method is only necessary\n",
        "    # if you want to use a Trainer's .predict() method (optional)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    # Pasos del proceso forward comunes entre train, val, test\n",
        "    def _shared_step(self, batch):\n",
        "        features, true_labels = batch\n",
        "        logits = self(features)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, true_labels) # cross entropy loss recibe logits y labels como entrada. No recibe probabilidades!\n",
        "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "        predicted_labels = torch.argmax(probs, dim=1)\n",
        "\n",
        "        return loss, true_labels, predicted_labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.train_acc(predicted_labels, true_labels)\n",
        "        self.log(\"train_acc\", self.train_acc, on_epoch=True, on_step=False)\n",
        "        return loss  # this is passed to the optimzer for training\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.log(\"valid_loss\", loss)\n",
        "        self.valid_acc(predicted_labels, true_labels)\n",
        "        self.log(\"valid_acc\", self.valid_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "        self.test_acc(predicted_labels, true_labels)\n",
        "        self.log(\"test_acc\", self.test_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAf9UGzLtRbw"
      },
      "source": [
        "## Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCSDifRhbkSv"
      },
      "outputs": [],
      "source": [
        "class CustomLoggingCallback(pl.Callback):\n",
        "    def on_train_epoch_start(self, trainer, pl_module):\n",
        "        self.epoch_start_time = time.time()\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch_duration = time.time() - self.epoch_start_time\n",
        "        epoch = trainer.current_epoch\n",
        "        train_loss = trainer.callback_metrics.get(\"train_loss\")\n",
        "        valid_loss = trainer.callback_metrics.get(\"valid_loss\")\n",
        "\n",
        "        output_str = f\"Epoch {epoch}: \"\n",
        "        if train_loss is not None:\n",
        "            output_str += f\"Train Loss: {train_loss:.4f}, \"\n",
        "        if valid_loss is not None:\n",
        "            output_str += f\"Valid Loss: {valid_loss:.4f}, \"\n",
        "        output_str += f\"Time per Epoch: {epoch_duration:.2f} seconds\"\n",
        "        print(output_str)\n",
        "\n",
        "custom_logger_callback = CustomLoggingCallback()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C86w3BYUZOIL"
      },
      "outputs": [],
      "source": [
        "# Inicialización del modulo lightning\n",
        "\n",
        "lightning_model = Lightning_CNN(pytorch_model, learning_rate=LEARNING_RATE, classes=CLASES)\n",
        "\n",
        "callback_check = ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"valid_acc\") # guardamos el mejor modelo monitoreado en la acc de validación. Por qué no la de entrenamiento?\n",
        "\n",
        "callback_tqdm = RichProgressBar(leave=True)\n",
        "\n",
        "logger = CSVLogger(save_dir=\"logs/\", name=\"complex-finetune-cnn-cifar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf0dXwlmZOFK"
      },
      "outputs": [],
      "source": [
        "#  Inicia entrenamiento\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=NUM_EPOCHS,\n",
        "                    callbacks=[callback_check, custom_logger_callback],\n",
        "                    accelerator=\"auto\",  # Uses GPUs or TPUs if available\n",
        "                    devices=\"auto\",  # Uses all available GPUs/TPUs if applicable\n",
        "                    logger=logger,\n",
        "                    log_every_n_steps=100,\n",
        "                    enable_progress_bar=ENABLE_PROGRESS_BAR)\n",
        "\n",
        "start_time = time.time()\n",
        "trainer.fit(model = lightning_model, datamodule = data_module)\n",
        "\n",
        "runtime = (time.time() - start_time) / 60\n",
        "print(f\"Tiempo de entrenamiento en minutos: {runtime:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DYyxrHugOC4"
      },
      "source": [
        "Non-trainable params:\n",
        "\n",
        "*   BatchNorm2d Running Statistics: running_mean and running_var in each batch normalization layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aer842ctxNzM"
      },
      "source": [
        "## Graficamos las curvas de aprendizaje del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDI5akWpZOBy"
      },
      "outputs": [],
      "source": [
        "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
        "\n",
        "aggreg_metrics = []\n",
        "agg_col = \"epoch\"\n",
        "for i, dfg in metrics.groupby(agg_col):\n",
        "    agg = dict(dfg.mean())\n",
        "    agg[agg_col] = i\n",
        "    aggreg_metrics.append(agg)\n",
        "\n",
        "df_metrics = pd.DataFrame(aggreg_metrics)\n",
        "df_metrics[[\"train_loss\", \"valid_loss\"]].plot(\n",
        "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"Loss\"\n",
        ")\n",
        "df_metrics[[\"train_acc\", \"valid_acc\"]].plot(\n",
        "    grid=True, legend=True, xlabel=\"Epoch\", ylabel=\"ACC\"\n",
        ")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4FDBGQ3xvHd"
      },
      "source": [
        "## Evaluamos el mejor modelo en el grupo de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8ZIocKjZN9a"
      },
      "outputs": [],
      "source": [
        "trainer.test(model = lightning_model, datamodule = data_module, ckpt_path = 'best') # cargamos el mejor checkpoint del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgnPlKj82EBw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pylight",
      "language": "python",
      "name": "pylight"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}